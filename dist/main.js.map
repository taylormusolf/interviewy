{"version":3,"file":"main.js","mappings":"YAAA,IAAIA,EAIAA,EAAQ,oD","sources":["webpack://interviewy/./src/index.js"],"sourcesContent":["let proxy;\nif(process.env.NODE_ENV === 'development'){\n    proxy = 'https://localhost:5002'\n}else{\n    proxy = 'https://cors-proxy-serv-d5884527e532.herokuapp.com'\n}\n\n//\n\nconst messages = [];\n\nconst chatFetch = async(messages)=>{\n\n    try{\n        const res = await fetch(`${proxy}/chat`,{\n            body: JSON.stringify(messages)\n        });\n        if(res.ok){\n            const data = await res.json();\n\n        } else {\n            throw res;\n        }\n\n    }catch(err){\n        console.error(err)\n    }\n    \n}\n\n\n\n\n// const getAiResponse = async (chatBot, chat, chatRequest) =>{\n//     const openai = new OpenAIApi(new Configuration({\n//       apiKey: process.env.CHAT_API_KEY\n//     }));\n//     const from = chatBot.from ? `from ${chatBot.from}` : '';\n//     const prompt = chatBot.prompt ? `${chatBot.prompt}` : '';\n//     const description = chatBot.description ? `${chatBot.description}` : '';\n//     const greeting = chatBot.greeting ? {role:'assistant', content: chatBot.greeting} : {};\n//     let systemPrompt = `You are ${chatBot.name} ${from}.  The user you are speaking with is ${chatRequest.name}. ${rules.join(' ')} ${description}. ${prompt}.`\n//     let messages = [{role:'system', content: systemPrompt}, greeting, ...chat.messages, chatRequest]\n  \n//     const res = await openai.createChatCompletion({\n//       model: \"gpt-4\",\n//       // model: \"gpt-3.5-turbo\",\n//       messages: messages,\n//       max_tokens: 150,\n//       temperature: 0.9\n//     });\n//     return res.data.choices[0].message\n//   }"],"names":["proxy"],"sourceRoot":""}